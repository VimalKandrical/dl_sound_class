{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "9ogoQuuTl5Ez",
        "e5nQ0g-4mHPg",
        "0tBd2sw71Fhh"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNsqSQEZmAB3ddwQook/yTI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VimalKandrical/dl_sound_class/blob/master/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HY4tXjk1lkqF",
        "colab_type": "text"
      },
      "source": [
        "#Classification of Environmental Sound\n",
        "**Autoren:**<br> Vimal Kandrical, Christian von Rotz\n",
        "\n",
        "**Daten:**<br>[Urbansound8k](https://www.kaggle.com/chrisfilo/urbansound8k) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ogoQuuTl5Ez",
        "colab_type": "text"
      },
      "source": [
        "# Einleitung"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGZfcWZvl9SC",
        "colab_type": "text"
      },
      "source": [
        "Im Rahmen des Moduls Deep Learning im CAS Machine Intelligence werden in diesem Projekt Tonaufnahmen von Umgebungsgeräuschen analysiert und mittels Deep Learning klassifiziert.  \n",
        "\n",
        "##Beschreibung der Daten (kaggle.com)\n",
        "\n",
        "This dataset contains 8732 labeled sound excerpts (<=4s) of urban sounds from 10 classes: air_conditioner, car_horn, children_playing, dog_bark, drilling, enginge_idling, gun_shot, jackhammer, siren, and street_music. The classes are drawn from the urban sound taxonomy. For a detailed description of the dataset and how it was compiled please refer to our paper.\n",
        "All excerpts are taken from field recordings uploaded to www.freesound.org. The files are pre-sorted into ten folds (folders named fold1-fold10) to help in the reproduction of and comparison with the automatic classification results reported in the article above.\n",
        "\n",
        "In addition to the sound excerpts, a CSV file containing metadata about each excerpt is also provided.\n",
        "\n",
        "**Audiofiles:**\n",
        "\n",
        "8732 audio files of urban sounds (see description above) in WAV format. The sampling rate, bit depth, and number of channels are the same as those of the original file uploaded to Freesound (and hence may vary from file to file).\n",
        "\n",
        "**Metadaten:**\n",
        "*   slicefilename:<br>\n",
        "    The name of the audio file. The name takes the following format:<br><br> [fsID]-4s[classID]-[occurrenceID]-[sliceID].wav<br><br>\n",
        "    \n",
        "    [fsID] = the Freesound ID of the recording from which this excerpt (slice) is taken\n",
        "   <br> [classID] = a numeric identifier of the sound class (see description of classID below for further details)\n",
        "   <br> [occurrenceID] = a numeric identifier to distinguish different occurrences of the sound within the original recording\n",
        "   <br> [sliceID] = a numeric identifier to distinguish different slices taken from the same occurrence\n",
        "*   fsID:<br>\n",
        "The Freesound ID of the recording from which this excerpt (slice) is taken\n",
        "*   start:<br>\n",
        "The start time of the slice in the original Freesound recording\n",
        "*   end:<br>\n",
        "The end time of slice in the original Freesound recording\n",
        "*   salience:<br>\n",
        "A (subjective) salience rating of the sound. 1 = foreground, 2 = background.\n",
        "*   fold:<br>\n",
        "The fold number (1-10) to which this file has been allocated.\n",
        "*   classID:<br>\n",
        "A numeric identifier of the sound class:\n",
        "    0 = airconditioner 1 = carhorn\n",
        "    2 = childrenplaying 3 = dogbark\n",
        "    4 = drilling\n",
        "    5 = engineidling 6 = gunshot\n",
        "    7 = jackhammer\n",
        "    8 = siren\n",
        "    9 = street_music\n",
        "*   class:<br>\n",
        " The class name: airconditioner, carhorn, childrenplaying, dogbark, drilling, engineidling, gunshot, jackhammer,\n",
        "    siren, street_music.\n",
        "\n",
        "**Bemerkungen:**<br>\n",
        "Auf kaggle wird explizit darauf hingewiesen, dass man die Daten nicht noch einmal mischen soll, sondern die vordefinierten 10 folds benützen soll. Nur so kann das erzielte Resultat mit anderen Resultaten verglichen. Zudem soll 10-fold cross validation angewendet werden, da die einzelnen folds nicht gleich schwer sind. Das Endresultat ist die durchschnittliche accuracy. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5nQ0g-4mHPg",
        "colab_type": "text"
      },
      "source": [
        "# Daten laden"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbETyhGI1eX0",
        "colab_type": "text"
      },
      "source": [
        "*Dieser Teil muss nur einmal ausgeführt werden, damit die Daten in Colab sind.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdhd8uSBmL5-",
        "colab_type": "text"
      },
      "source": [
        "Google Colab benötigt Zugriff auf Kaggle via API. Der API Token muss unter content abliegen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-A21x4U2mSL7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "os.chdir(\"/content\")\n",
        "os.listdir()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d5ITnFUtT-i",
        "colab_type": "text"
      },
      "source": [
        "Zugriffsrechte anpassen und File downloaden"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEKRaPuwrcuI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp \"/content/kaggle.json\" ~/.kaggle/\n",
        "!chmod 600 \"/content/kaggle.json\"\n",
        "!kaggle datasets download -d chrisfilo/urbansound8k"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcVqP2Z3vGn2",
        "colab_type": "text"
      },
      "source": [
        "Zipfile entpacken"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLeY6lcZvTht",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir(\"/content\")\n",
        "!unzip urbansound8k.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOamL8A2iPFr",
        "colab_type": "text"
      },
      "source": [
        "# Voranalyse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhjZDgEiihbr",
        "colab_type": "text"
      },
      "source": [
        "Bevor die Audiofiles genutzt werden können, muss ihr Aufbau verstanden werden. Diese Informationen stehen ganz am Anfang des WAV Files im sogenannten Header (44 Bytes lang). Folgende Informationen sind relevant:\n",
        "\n",
        "Information  | Position\n",
        "  ------------- | -------------\n",
        "  Anzahl Channels (mono/stereo)  | 23-24\n",
        "  Sample rate  | 25-28\n",
        "Bits pro Sample | 35-36\n",
        "\n",
        "(Details zum Aufbau eines WAV (RIFF) Files können [hier](http://www.topherlee.com/software/pcm-tut-wavformat.html) nachgelesen werden.)\n",
        "\n",
        "Hier ein Beispiel:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dTzEG123aVp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import struct\n",
        "import os\n",
        "\n",
        "\n",
        "def readheader(filename):\n",
        "  with open(filename, \"rb\") as wavfile:\n",
        "    header = wavfile.read(44)\n",
        "    channels = struct.unpack(\"<H\", header[22:24])[0]\n",
        "    samplerate = struct.unpack(\"<I\", header[24:28])[0]\n",
        "    bitsprosample = struct.unpack(\"<H\", header[34:36])[0]\n",
        "  return (channels, samplerate, bitsprosample)\n",
        "\n",
        "beispiel = readheader(\"/content/fold1/101415-3-0-2.wav\")\n",
        "print(\"Anzahl Channels: \", beispiel[0])\n",
        "print(\"Sample rate: \", beispiel[1])\n",
        "print(\"Bits pro Sample: \", beispiel[2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktE8L3mtz5kz",
        "colab_type": "text"
      },
      "source": [
        "Analog werden nun alle Audiofiles gelesen und die Charakteristik in einem Dataframe festgehalten."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AG80p8FH2a5e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.options.display.max_columns = 10\n",
        "\n",
        "metadaten = pd.read_csv(\"/content/UrbanSound8K.csv\")\n",
        "#print(metadaten.head()) \n",
        "#print(metadaten.dtypes) -> passt soweit\n",
        "\n",
        "informationen = []\n",
        "\n",
        "for i, r in metadaten.iterrows():\n",
        "  audiofile = os.path.join(os.path.abspath(\"/content/\"),\"fold\"+str(r[\"fold\"])+\"/\",str(r[\"slice_file_name\"]))\n",
        "  informationen.append(readheader(audiofile))\n",
        "\n",
        "aufbau = pd.DataFrame(informationen, columns=['anz_channels','samplerate','bits_pro_sample'])\n",
        "print(aufbau[\"anz_channels\"].value_counts())\n",
        "print(aufbau[\"samplerate\"].value_counts())\n",
        "print(aufbau[\"bits_pro_sample\"].value_counts())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThqI54Y8A-_Y",
        "colab_type": "text"
      },
      "source": [
        "Es lässt sich festhalten, dass die Audiofiles bzgl. Anzahl Channels (Mono/Stereo), Samplerate und Bits pro Sample variieren."
      ]
    }
  ]
}